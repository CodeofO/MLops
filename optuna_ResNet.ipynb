{"cells":[{"cell_type":"markdown","metadata":{"id":"LCYXr7UIWzLq"},"source":["This Kernel for someone want to deep dive into image classification. I use CNN for classification model. If you found this Kernel helpful please up vote it. If you have some feedback and question don't forget to comment below. \n","\n","I have simplier model with \n","* https://www.kaggle.com/uysimty/get-start-image-classification"]},{"cell_type":"markdown","metadata":{"_uuid":"fe76d1d1ded592430e7548feacfa38dc42f085d9","id":"vo30nKFIWzLu"},"source":["# Import Library"]},{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","executionInfo":{"elapsed":4692,"status":"ok","timestamp":1673953310278,"user":{"displayName":"정근오","userId":"08471948723463941360"},"user_tz":-540},"id":"b1IOCzZ3WzLv"},"outputs":[],"source":["import numpy as np\n","import pandas as pd \n","from keras.preprocessing.image import ImageDataGenerator # 이미지 데이터의 배치를 생성, 이미지 전처리에 사용\n","from keras.utils import to_categorical # 여러 개의 Y값을 0과 1로만 이루어진 형태로 바꿔주는 one-hot-encoding\n","from sklearn.model_selection import train_test_split # scikit-learn 패키지 중 model_selection에 데이터 분할을 위한 train_test_split 함수가 있음.\n","import matplotlib.pyplot as plt\n","import random\n","import os # os.listdir을 쓰기 위해서\n"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20310,"status":"ok","timestamp":1673953330586,"user":{"displayName":"정근오","userId":"08471948723463941360"},"user_tz":-540},"id":"EpM7227UWzLx","outputId":"76c96717-9674-4af5-91ed-4af45e73ab03"},"outputs":[{"name":"stderr","output_type":"stream","text":["/Users/jeong-geun-o/miniconda3/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["import urllib\n","import optuna\n","from optuna.integration import TFKerasPruningCallback\n","from optuna.trial import TrialState\n","\n","import tensorflow as tf"]},{"cell_type":"markdown","metadata":{"id":"Vkm08GL4WzLy"},"source":["# Define Constants"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1673953330587,"user":{"displayName":"정근오","userId":"08471948723463941360"},"user_tz":-540},"id":"Px4k1x4dWzLy"},"outputs":[],"source":["opener = urllib.request.build_opener()\n","opener.addheaders = [(\"User-agent\", \"Mozilla/5.0\")]\n","urllib.request.install_opener(opener)"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1673953330587,"user":{"displayName":"정근오","userId":"08471948723463941360"},"user_tz":-540},"id":"qdT5YnCrWzLy"},"outputs":[],"source":["FAST_RUN = False # 아래에 사용됨\n","IMAGE_WIDTH=128 # 이미지 넓이(행)\n","IMAGE_HEIGHT=128 # 이미지 높이(열)\n","IMAGE_SIZE=(IMAGE_WIDTH, IMAGE_HEIGHT)\n","IMAGE_CHANNELS=3 # 이미지 channel(depth)"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1673953330588,"user":{"displayName":"정근오","userId":"08471948723463941360"},"user_tz":-540},"id":"uvufoiySWzLz"},"outputs":[],"source":["BATCHSIZE = 256\n","CLASSES = 2\n","EPOCHS = 7\n","N_TRAIN_EXAMPLES = 3000\n","STEPS_PER_EPOCH = int(N_TRAIN_EXAMPLES / BATCHSIZE)\n","VALIDATION_STEPS = 30"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1673953330588,"user":{"displayName":"정근오","userId":"08471948723463941360"},"user_tz":-540},"id":"dsjY-dACWzLz"},"outputs":[],"source":["global train_df\n","global validate_df"]},{"cell_type":"markdown","metadata":{"_uuid":"7335a579cc0268fba5d34d6f7558f33c187eedb3","id":"9tGSfrdvWzL0"},"source":["# Prepare Traning Data"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":36875,"status":"ok","timestamp":1673953367456,"user":{"displayName":"정근오","userId":"08471948723463941360"},"user_tz":-540},"id":"kJpJHeAuW6G8","outputId":"004cb7c3-445e-482b-c592-706bff467606"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading dogs-vs-cats.zip to /Users/jeong-geun-o/Desktop/MLops\n","100%|███████████████████████████████████████▊| 809M/812M [00:41<00:00, 39.0MB/s]\n","100%|████████████████████████████████████████| 812M/812M [00:41<00:00, 20.7MB/s]\n"]}],"source":["# 케글 데이터 다운받기\n","import os\n","\n","# os.environ을 이용하여 Kaggle API Username, Key 세팅하기\n","# os.environ['KAGGLE_USERNAME'] = ''\n","# os.environ['KAGGLE_KEY']=''\n","\n","# 데이터셋 다운로드 \n","\n","!kaggle competitions download -c dogs-vs-cats"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!unzip '*.zip' \n","!unzip 'train.zip' \n","!unzip 'test1.zip' "]},{"cell_type":"code","execution_count":62,"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","colab":{"base_uri":"https://localhost:8080/","height":433},"executionInfo":{"elapsed":93,"status":"ok","timestamp":1673953395410,"user":{"displayName":"정근오","userId":"08471948723463941360"},"user_tz":-540},"id":"OMg-VfTmWzL0","outputId":"d592d974-aa34-42a5-93b1-d5061e3f8cdf"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import glob\n","\n","\n","def train_set_name_changer():\n","    train_files = [i[6:] for i in glob.glob('train/*.jpg')]\n","    train_labels = [i[6:9] for i in glob.glob('train/*.jpg')]\n","\n","    df = pd.DataFrame({\n","        'filename':train_files,\n","        'category':train_labels\n","    })\n","\n","train_set_name_changer()"]},{"cell_type":"markdown","metadata":{"id":"9In6ku90WzL0"},"source":["# Prepare data"]},{"cell_type":"markdown","metadata":{"id":"FWZJN1cZWzL1"},"source":["Because we will use image genaretor `with class_mode=\"categorical\"`. We need to convert column category into string. Then imagenerator will convert it one-hot encoding which is good for our classification. \n","\n","So we will convert 1 to dog and 0 to cat"]},{"cell_type":"code","execution_count":38,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":221},"executionInfo":{"elapsed":88,"status":"ok","timestamp":1673953395411,"user":{"displayName":"정근오","userId":"08471948723463941360"},"user_tz":-540},"id":"e8VGX_bEWzL1","outputId":"86ec3779-0d53-4458-81d4-2fa6ad20abf1"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>filename</th>\n","      <th>category</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>dog.8011.jpg</td>\n","      <td>dog</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>cat.5077.jpg</td>\n","      <td>cat</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>dog.7322.jpg</td>\n","      <td>dog</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>cat.2718.jpg</td>\n","      <td>cat</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>cat.10151.jpg</td>\n","      <td>cat</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        filename category\n","0   dog.8011.jpg      dog\n","1   cat.5077.jpg      cat\n","2   dog.7322.jpg      dog\n","3   cat.2718.jpg      cat\n","4  cat.10151.jpg      cat"]},"execution_count":38,"metadata":{},"output_type":"execute_result"}],"source":["df.head() # category 확인"]},{"cell_type":"code","execution_count":39,"metadata":{"_uuid":"4eeb7af8dcf02c4ef5ca744c8305c51a2f5cedef","executionInfo":{"elapsed":86,"status":"ok","timestamp":1673953395411,"user":{"displayName":"정근오","userId":"08471948723463941360"},"user_tz":-540},"id":"zl5oGiOLWzL2"},"outputs":[],"source":["train_df, validate_df = train_test_split(df, test_size=0.20, random_state=42)\n","# df: 분할시킬 data (DataFrame)\n","# test_size: test dataset의 비율이나 갯수(default=0.25) -> 여기서는 validation set이라 할 수 있다.\n","# random state: 데이터 분할시 셔플이 이루어지는데 이를 위한 시드값\n","# shuffle: 셔플여부설정 (default=True)\n","\n","train_df = train_df.reset_index(drop=True) # index를 reset함 -> drop: index로 세팅한 열을 데이터프레임내에서 삭제할지 여부를 결정한다.\n","validate_df = validate_df.reset_index(drop=True)"]},{"cell_type":"code","execution_count":40,"metadata":{"_uuid":"ae3dec0361f0443132d0309d3b883ee80070cf9f","executionInfo":{"elapsed":85,"status":"ok","timestamp":1673953395411,"user":{"displayName":"정근오","userId":"08471948723463941360"},"user_tz":-540},"id":"XTmHV3QnWzL2"},"outputs":[],"source":["total_train = train_df.shape[0]\n","total_validate = validate_df.shape[0]\n","batch_size=15"]},{"cell_type":"code","execution_count":41,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":86,"status":"ok","timestamp":1673953395412,"user":{"displayName":"정근오","userId":"08471948723463941360"},"user_tz":-540},"id":"o5_0RzEnWzL2","outputId":"c3c5355e-33c1-4f4a-f2de-1b64ec5e9cfc"},"outputs":[{"name":"stdout","output_type":"stream","text":["(20000, 2)\n","(5000, 2)\n"]}],"source":["# 제가 뭔지 확인해 본거에요.\n","print(train_df.shape) \n","print(validate_df.shape) "]},{"cell_type":"code","execution_count":42,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>filename</th>\n","      <th>category</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>cat.11282.jpg</td>\n","      <td>cat</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>cat.7693.jpg</td>\n","      <td>cat</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>cat.4977.jpg</td>\n","      <td>cat</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>dog.9403.jpg</td>\n","      <td>dog</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>cat.10150.jpg</td>\n","      <td>cat</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>19995</th>\n","      <td>dog.2721.jpg</td>\n","      <td>dog</td>\n","    </tr>\n","    <tr>\n","      <th>19996</th>\n","      <td>dog.3974.jpg</td>\n","      <td>dog</td>\n","    </tr>\n","    <tr>\n","      <th>19997</th>\n","      <td>dog.10427.jpg</td>\n","      <td>dog</td>\n","    </tr>\n","    <tr>\n","      <th>19998</th>\n","      <td>cat.731.jpg</td>\n","      <td>cat</td>\n","    </tr>\n","    <tr>\n","      <th>19999</th>\n","      <td>dog.6540.jpg</td>\n","      <td>dog</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>20000 rows × 2 columns</p>\n","</div>"],"text/plain":["            filename category\n","0      cat.11282.jpg      cat\n","1       cat.7693.jpg      cat\n","2       cat.4977.jpg      cat\n","3       dog.9403.jpg      dog\n","4      cat.10150.jpg      cat\n","...              ...      ...\n","19995   dog.2721.jpg      dog\n","19996   dog.3974.jpg      dog\n","19997  dog.10427.jpg      dog\n","19998    cat.731.jpg      cat\n","19999   dog.6540.jpg      dog\n","\n","[20000 rows x 2 columns]"]},"execution_count":42,"metadata":{},"output_type":"execute_result"}],"source":["train_df"]},{"cell_type":"markdown","metadata":{"_uuid":"ff760be9104f7d9492467b8d9d3405011aa77d11","id":"QwSYVQ7WWzL3"},"source":["# Traning Generator"]},{"cell_type":"code","execution_count":45,"metadata":{"executionInfo":{"elapsed":516,"status":"ok","timestamp":1673953395920,"user":{"displayName":"정근오","userId":"08471948723463941360"},"user_tz":-540},"id":"860W-RkTWzL3"},"outputs":[],"source":["def train_dataset(train_df):\n","    # 신경망 모델의 성능을 높이기 위한 위한 \"데이터 부풀리기(Data augmentation)\"\n","    train_datagen = ImageDataGenerator(\n","        rotation_range=15,\n","        rescale=1./255,\n","        shear_range=0.1,\n","        zoom_range=0.2,\n","        horizontal_flip=True,\n","        width_shift_range=0.1,\n","        height_shift_range=0.1\n","    )\n","    # rotation_range : 지정된 각도 \"범위\"내에서 임의로 원본이미지를 회전시킨다. // 단위:(도) -> 여기서는 15니까, 0도에서 15도 사이\n","    # rescale : byte와 관련이 있는듯 255라는 숫자가\n","    # shear_range : 밀림 강도 범위내에서 임의로 원본이미지를 변형시킴\n","\n","    # zoom_range : 지정된 확대/축소 범위내에서 임의로 원본이미지를 확대/축소. “1 - 수치”부터 “1 + 수치”사이 범위로 확대/축소.\n","    #              예를 들어 0.2이라면, 0.8배에서 1.2배 크기 변화를 시킵니다.\n","\n","    # horizontal_flip : 수평방향으로 뒤집느냐 마느냐\n","\n","    # width_shift_range : 지정된 \"수평방향\" 이동 범위내에서 임의로 원본이미지를 이동시킴. 수치는 \"전체 넓이\"의 비율(실수)로 나타냄.\n","    #                     예를 들어 0.1이고 전체 넓이가 100이면, 10픽셀 내외로 \"좌우\" 이동.\n","\n","    # height_shift_range : 지정된 \"수직방향\" 이동 범위내에서 임의로 원본이미지를 이동시킴. 수치는 \"전체 높이\"의 비율(실수)로 나타냄..\n","    #                       예를 들어 0.1이고 전체 높이가 100이면, 10픽셀 내외로 \"상하\" 이동.\n","\n","\n","    # 'dataframe'과 '디렉토리'의 위치를 전달받아 증강/정규화된 데이터의 \"배치\"를 생성.\n","    train_generator = train_datagen.flow_from_dataframe( \n","        train_df, # DataFrame (전체 중에 80%만 있음)\n","        \"train/\", # 문자열, 이미지를 읽을 '디렉토리'의 경로 (전체 data가 있음) \n","        x_col='filename', # train_df 데이터프레임에 filename col의 값들을 가져옴\n","        y_col='category', # train_df 데이터프레임에 category col의 값들을 가져옴\n","        target_size=IMAGE_SIZE, # \n","        class_mode='categorical', # 2D numpy array of one-hot encoded labels. Supports multi-label output.\n","        batch_size=batch_size # batch size\n","    )\n","    return train_generator"]},{"cell_type":"code","execution_count":46,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1673953395920,"user":{"displayName":"정근오","userId":"08471948723463941360"},"user_tz":-540},"id":"h0dTZKjwWzL3","outputId":"e3bce7e0-b760-4f90-eef2-e9ec228da898"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 20000 validated image filenames belonging to 2 classes.\n"]},{"data":{"text/plain":["<keras.preprocessing.image.DataFrameIterator at 0x2c0b934c0>"]},"execution_count":46,"metadata":{},"output_type":"execute_result"}],"source":["train_ds = train_dataset(train_df)\n","train_ds"]},{"cell_type":"markdown","metadata":{"_uuid":"859c7b2857939c19fd2e3bb32839c9f7deb5aa3f","id":"aH7IvqFSWzL4"},"source":["### Validation Generator"]},{"cell_type":"code","execution_count":47,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1673953395920,"user":{"displayName":"정근오","userId":"08471948723463941360"},"user_tz":-540},"id":"Hry9fVG_WzL4"},"outputs":[],"source":["def validate_dataset(validate_df):\n","    # 위에 train_datagen과는 다르게 rescale만 해줌. (검증하는 거니까!)\n","    # rescale 하는 이유: 정규화 과정임. image가 0~255까지 값을 가지는 2차원 배열인데, 0~255 사이의 값을\n","    #                   0.0과 1.0사이의 값으로 바꾸기 위함이다.\n","    #                   활성화함수 및 오류역전파 알고리즘은 0.0과 1.0사이의 값을 좋아하기 때문이다.\n","    validation_datagen = ImageDataGenerator(rescale=1./255)\n","\n","    # 위에 있는 train_generator와 같다\n","    validation_generator = validation_datagen.flow_from_dataframe(\n","        validate_df, \n","        \"train/\", \n","        x_col='filename',\n","        y_col='category',\n","        target_size=IMAGE_SIZE,\n","        class_mode='categorical',\n","        batch_size=batch_size\n","    )\n","\n","    return validation_generator "]},{"cell_type":"code","execution_count":48,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1673953395921,"user":{"displayName":"정근오","userId":"08471948723463941360"},"user_tz":-540},"id":"5U4llFrtWzL4","outputId":"8ff25ab1-f368-4467-a753-8a24e9ba6790"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 5000 validated image filenames belonging to 2 classes.\n"]},{"data":{"text/plain":["<keras.preprocessing.image.DataFrameIterator at 0x2865ce9b0>"]},"execution_count":48,"metadata":{},"output_type":"execute_result"}],"source":["validate_ds = validate_dataset(validate_df)\n","validate_ds"]},{"cell_type":"markdown","metadata":{"_uuid":"810ddf1373d9db470ed48da4f30ca5a6c1274435","id":"stK2JUshWzL5"},"source":["Seem to be nice "]},{"cell_type":"markdown","metadata":{"id":"RCuetuwXWzL5"},"source":["* **Input Layer**: It represent input image data. It will reshape image into single diminsion array. Example your image is 64x64 = 4096, it will convert to (4096,1) array.\n","* **Conv Layer**: This layer will extract features from image.\n","* **Pooling Layer**: This layerreduce the spatial volume of input image after convolution.\n","* **Fully Connected Layer**: It connect the network from a layer to another layer\n","* **Output Layer**: It is the predicted values layer. "]},{"cell_type":"code","execution_count":49,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1673953427089,"user":{"displayName":"정근오","userId":"08471948723463941360"},"user_tz":-540},"id":"3gScFSEMWzL5"},"outputs":[],"source":["from keras.applications import VGG16\n","from keras.applications.resnet import ResNet50\n","\n","def create_model(trial):\n","    # Hyperparameters to be tuned by Optuna.\n","    learning_rate = trial.suggest_float(\"learning_rate\", 1e-4, 1e-1, log=True)\n","    momentum = trial.suggest_float(\"momentum\", 0.0, 1.0)\n","    units = trial.suggest_categorical(\"units\", [32, 64, 128, 256, 512])\n","    \n","    conv_base = ResNet50(weights='imagenet',\n","                    include_top=False,\n","                    input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS))\n","\n","    model = tf.keras.Sequential() # 가장 자주 사용하는 구조인 층을 순서대로 쌓아 올린 네트워크{keras 사용 - 모델을 정의(생성)}\n","    conv_base.trainable = False  # Freeze weights of conv_base layers (VGG16)\n","\n","    # Convolution\n","    # 인공신경망 모델을 효율적으로 학습시키기 윈한 개선 방법들 (BatchNormalization, Dropout, ModelEnsemble)\n","    model.add(conv_base)\n","    model.add(tf.keras.layers.Flatten()) # - 이 층에는 학습되는 가중치가 없고 데이터를 변환하기만 한다.(1차원 vector으로 바꿈)\n","                        # - 이 층은 하나의 layer에 있는 모든 neuron을 또 다른 layer의 모든 neuron과 연결 시켜준다.\n","    model.add(tf.keras.layers.Dense(256, activation='relu')) # dense로 층을 쌓음 - 첫번째 Dense층은 512개의 노드를 가짐\n","    model.add(tf.keras.layers.BatchNormalization())\n","    model.add(tf.keras.layers.Dropout(0.5))\n","    model.add(tf.keras.layers.Dense(2, activation='softmax')) # 2: because we have cat and dog classes\n","                                            # 마지막 층은 2개의 노드의 소프트맥스층 : 이 층은 2개의 확률을 반환하고 반환된 값의 전체 합은 1이다. \n","                                            # 각 노드는 현재 이미지가 2개 클래스 중 하나에 속할 확률을 출력\n","\n","    # Compile model.\n","    model.compile(\n","        optimizer=tf.keras.optimizers.SGD(\n","            learning_rate=learning_rate, momentum=momentum, nesterov=True\n","        ),\n","        loss=\"categorical_crossentropy\",\n","        metrics=[\"accuracy\"],\n","    )\n","\n","    return model"]},{"cell_type":"code","execution_count":55,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1673953431456,"user":{"displayName":"정근오","userId":"08471948723463941360"},"user_tz":-540},"id":"ATGKWO_IWzL6"},"outputs":[],"source":["def objective(trial):\n","    global train_df\n","    global validate_df\n","    # Clear clutter from previous TensorFlow graphs.\n","    tf.keras.backend.clear_session()\n","\n","    # Metrics to be monitored by Optuna.\n","    if tf.__version__ >= \"2\":\n","        monitor = \"val_accuracy\"\n","    else:\n","        monitor = \"val_acc\"\n","\n","    # Create tf.keras model instance.\n","    model = create_model(trial)\n","\n","    # Create dataset instance.\n","    ds_train = train_dataset(train_df)\n","    ds_eval = validate_dataset(validate_df)\n","\n","    # Create callbacks for early stopping and pruning.\n","    callbacks = [\n","        tf.keras.callbacks.EarlyStopping(patience=3),\n","        TFKerasPruningCallback(trial, monitor),\n","    ]\n","\n","    # Train model.\n","    history = model.fit(\n","        ds_train,\n","        epochs=EPOCHS,\n","        steps_per_epoch=STEPS_PER_EPOCH,\n","        validation_data=ds_eval,\n","        validation_steps=VALIDATION_STEPS,\n","        callbacks=callbacks,\n","    )\n","    model.save_weights(\"res.h5\") \n","    return history.history[monitor][-1]"]},{"cell_type":"code","execution_count":51,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1673953437453,"user":{"displayName":"정근오","userId":"08471948723463941360"},"user_tz":-540},"id":"oUhNuAzKWzL6"},"outputs":[],"source":["def show_result(study):\n","\n","    pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n","    complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n","\n","    print(\"Study statistics: \")\n","    print(\"  Number of finished trials: \", len(study.trials))\n","    print(\"  Number of pruned trials: \", len(pruned_trials))\n","    print(\"  Number of complete trials: \", len(complete_trials))\n","\n","    print(\"Best trial:\")\n","    trial = study.best_trial\n","\n","    print(\"  Value: \", trial.value)\n","\n","    print(\"  Params: \")\n","    for key, value in trial.params.items():\n","        print(\"    {}: {}\".format(key, value))\n","    \n","    return "]},{"cell_type":"code","execution_count":52,"metadata":{"executionInfo":{"elapsed":601,"status":"ok","timestamp":1673953445847,"user":{"displayName":"정근오","userId":"08471948723463941360"},"user_tz":-540},"id":"TbODXTSUWzL7"},"outputs":[],"source":["def main():\n","\n","    study = optuna.create_study(\n","        direction=\"maximize\", pruner=optuna.pruners.MedianPruner(n_startup_trials=2)\n","    )\n","\n","    study.optimize(objective, n_trials=trials, timeout=600)\n","\n","    show_result(study)"]},{"cell_type":"code","execution_count":56,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":447833,"status":"ok","timestamp":1673954175699,"user":{"displayName":"정근오","userId":"08471948723463941360"},"user_tz":-540},"id":"Wu1EM_i5WzL7","outputId":"1684aaf8-ab8e-4e02-8437-0a5c5028342b"},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2023-01-18 18:35:16,451]\u001b[0m A new study created in memory with name: no-name-605222d1-1600-405c-86cc-62813ad6d0f7\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Found 20000 validated image filenames belonging to 2 classes.\n","Found 5000 validated image filenames belonging to 2 classes.\n","Epoch 1/7\n"]},{"name":"stderr","output_type":"stream","text":["2023-01-18 18:35:20.776040: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"]},{"name":"stdout","output_type":"stream","text":["11/11 [==============================] - ETA: 0s - loss: 1.1112 - accuracy: 0.6182"]},{"name":"stderr","output_type":"stream","text":["2023-01-18 18:35:24.459785: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"]},{"name":"stdout","output_type":"stream","text":["11/11 [==============================] - 10s 605ms/step - loss: 1.1112 - accuracy: 0.6182 - val_loss: 7.7323 - val_accuracy: 0.4800\n","Epoch 2/7\n","11/11 [==============================] - 3s 311ms/step - loss: 0.8731 - accuracy: 0.5576 - val_loss: 6.5106 - val_accuracy: 0.4956\n","Epoch 3/7\n","11/11 [==============================] - 3s 305ms/step - loss: 0.7705 - accuracy: 0.5394 - val_loss: 1.1647 - val_accuracy: 0.5067\n","Epoch 4/7\n","11/11 [==============================] - 3s 317ms/step - loss: 0.6549 - accuracy: 0.6424 - val_loss: 2.0622 - val_accuracy: 0.4622\n","Epoch 5/7\n","11/11 [==============================] - 3s 308ms/step - loss: 0.6884 - accuracy: 0.6364 - val_loss: 4.9004 - val_accuracy: 0.4889\n","Epoch 6/7\n","11/11 [==============================] - 3s 312ms/step - loss: 0.8189 - accuracy: 0.5576 - val_loss: 6.3293 - val_accuracy: 0.4889\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2023-01-18 18:35:45,515]\u001b[0m Trial 0 finished with value: 0.4888888895511627 and parameters: {'learning_rate': 0.011844043877846362, 'momentum': 0.2663887638015643, 'units': 64}. Best is trial 0 with value: 0.4888888895511627.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Found 20000 validated image filenames belonging to 2 classes.\n","Found 5000 validated image filenames belonging to 2 classes.\n","Epoch 1/7\n"]},{"name":"stderr","output_type":"stream","text":["2023-01-18 18:35:48.754755: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"]},{"name":"stdout","output_type":"stream","text":["11/11 [==============================] - ETA: 0s - loss: 1.0730 - accuracy: 0.4909"]},{"name":"stderr","output_type":"stream","text":["2023-01-18 18:35:52.023373: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"]},{"name":"stdout","output_type":"stream","text":["11/11 [==============================] - 8s 540ms/step - loss: 1.0730 - accuracy: 0.4909 - val_loss: 13.1246 - val_accuracy: 0.4822\n","Epoch 2/7\n","11/11 [==============================] - 4s 352ms/step - loss: 0.9130 - accuracy: 0.5091 - val_loss: 11.8216 - val_accuracy: 0.4867\n","Epoch 3/7\n","11/11 [==============================] - 3s 310ms/step - loss: 1.0801 - accuracy: 0.4848 - val_loss: 5.7190 - val_accuracy: 0.4778\n","Epoch 4/7\n","11/11 [==============================] - 3s 324ms/step - loss: 0.8432 - accuracy: 0.6000 - val_loss: 51.6046 - val_accuracy: 0.4978\n","Epoch 5/7\n","11/11 [==============================] - 3s 322ms/step - loss: 1.0121 - accuracy: 0.5818 - val_loss: 15.1584 - val_accuracy: 0.4711\n","Epoch 6/7\n","11/11 [==============================] - 3s 308ms/step - loss: 0.8420 - accuracy: 0.6061 - val_loss: 14.8323 - val_accuracy: 0.4600\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2023-01-18 18:36:12,903]\u001b[0m Trial 1 finished with value: 0.46000000834465027 and parameters: {'learning_rate': 0.03737318665879586, 'momentum': 0.6193071258999909, 'units': 128}. Best is trial 0 with value: 0.4888888895511627.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Found 20000 validated image filenames belonging to 2 classes.\n","Found 5000 validated image filenames belonging to 2 classes.\n","Epoch 1/7\n"]},{"name":"stderr","output_type":"stream","text":["2023-01-18 18:36:16.329803: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"]},{"name":"stdout","output_type":"stream","text":["11/11 [==============================] - ETA: 0s - loss: 0.8520 - accuracy: 0.5576"]},{"name":"stderr","output_type":"stream","text":["2023-01-18 18:36:19.828802: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"]},{"name":"stdout","output_type":"stream","text":["11/11 [==============================] - 9s 636ms/step - loss: 0.8520 - accuracy: 0.5576 - val_loss: 0.6819 - val_accuracy: 0.5822\n","Epoch 2/7\n","11/11 [==============================] - 4s 323ms/step - loss: 0.9879 - accuracy: 0.5576 - val_loss: 0.6906 - val_accuracy: 0.5267\n","Epoch 3/7\n","11/11 [==============================] - 3s 306ms/step - loss: 0.9562 - accuracy: 0.5091 - val_loss: 0.7614 - val_accuracy: 0.5156\n","Epoch 4/7\n","11/11 [==============================] - 3s 303ms/step - loss: 0.7785 - accuracy: 0.5879 - val_loss: 0.7056 - val_accuracy: 0.5111\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[32m[I 2023-01-18 18:36:34,372]\u001b[0m Trial 2 finished with value: 0.5111111402511597 and parameters: {'learning_rate': 0.0007890436524346838, 'momentum': 0.23940193826459555, 'units': 64}. Best is trial 2 with value: 0.5111111402511597.\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["Study statistics: \n","  Number of finished trials:  3\n","  Number of pruned trials:  0\n","  Number of complete trials:  3\n","Best trial:\n","  Value:  0.5111111402511597\n","  Params: \n","    learning_rate: 0.0007890436524346838\n","    momentum: 0.23940193826459555\n","    units: 64\n"]}],"source":["trials = 3\n","\n","if __name__ == \"__main__\":\n","    main()"]},{"cell_type":"code","execution_count":71,"metadata":{},"outputs":[{"ename":"TypeError","evalue":"get_all_study_summaries() missing 1 required positional argument: 'storage'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[71], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m optuna\u001b[39m.\u001b[39;49mget_all_study_summaries()\n","\u001b[0;31mTypeError\u001b[0m: get_all_study_summaries() missing 1 required positional argument: 'storage'"]}],"source":["optuna.get_all_study_summaries()"]},{"cell_type":"markdown","metadata":{"_uuid":"aa1fbc4081ae0de2993188b2bf658a0be5bc0687","id":"Mpz52zuaWzL8"},"source":["# Save Model"]},{"cell_type":"code","execution_count":63,"metadata":{"_uuid":"c35e70d3e1e4834dbbf840fa0ea08c049bfcd915","id":"Ek7SYkB4WzL9"},"outputs":[],"source":["test_filenames = os.listdir(\"test1\") # test에 있는 list들을 가져옴\n","test_df = pd.DataFrame({                                       # 데이터프레임을 생성\n","    'filename': test_filenames                                 # filename이라는 col에 test_filenames값을 가져옴\n","})\n","nb_samples = test_df.shape[0] # test dataset data 갯수"]},{"cell_type":"code","execution_count":66,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>filename</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>9733.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>63.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>6400.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>823.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4217.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>12495</th>\n","      <td>3561.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>12496</th>\n","      <td>8434.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>12497</th>\n","      <td>7707.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>12498</th>\n","      <td>6419.jpg</td>\n","    </tr>\n","    <tr>\n","      <th>12499</th>\n","      <td>1376.jpg</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>12500 rows × 1 columns</p>\n","</div>"],"text/plain":["       filename\n","0      9733.jpg\n","1        63.jpg\n","2      6400.jpg\n","3       823.jpg\n","4      4217.jpg\n","...         ...\n","12495  3561.jpg\n","12496  8434.jpg\n","12497  7707.jpg\n","12498  6419.jpg\n","12499  1376.jpg\n","\n","[12500 rows x 1 columns]"]},"execution_count":66,"metadata":{},"output_type":"execute_result"}],"source":["test_df"]},{"cell_type":"code","execution_count":64,"metadata":{"id":"PJwXUTSsWzL-"},"outputs":[{"data":{"text/plain":["(12500, 1)"]},"execution_count":64,"metadata":{},"output_type":"execute_result"}],"source":["test_df.shape"]},{"cell_type":"markdown","metadata":{"_uuid":"291bc3996dce8d05e174b27d64f03996d3e8038e","id":"woVjRqj-WzL_"},"source":["# Create Testing Generator"]},{"cell_type":"code","execution_count":67,"metadata":{"_uuid":"52249ec1c35fb1be3adef386be245de3794e55aa","id":"g6tKonh2WzL_"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 12500 validated image filenames.\n"]}],"source":["# rescale만 해줌. (검증하는 거니까!)\n","# rescale 하는 이유: 정규화 과정임. image가 0~255까지 값을 가지는 2차원 배열인데, 0~255 사이의 값을\n","#                   0.0과 1.0사이의 값으로 바꾸기 위함이다.\n","#                   활성화함수 및 오류역전파 알고리즘은 0.0과 1.0사이의 값을 좋아하기 때문이다.\n","test_gen = ImageDataGenerator(rescale=1./255)\n","\n","test_generator = test_gen.flow_from_dataframe(\n","    test_df, \n","    \"test1/\", \n","    x_col='filename',\n","    y_col=None,\n","    class_mode=None,\n","    target_size=IMAGE_SIZE,\n","    batch_size=batch_size,\n","    shuffle=False\n",")\n","\n","# shuffle을 쓰지 않음"]},{"cell_type":"markdown","metadata":{"_uuid":"2fa580afca2931ec5ce374e732d8c1789d03f2ed","id":"CibQvVORWzL_"},"source":["# Predict"]},{"cell_type":"code","execution_count":74,"metadata":{},"outputs":[],"source":["def show_result(study):\n","\n","    pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n","    complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n","\n","    print(\"Study statistics: \")\n","    print(\"  Number of finished trials: \", len(study.trials))\n","    print(\"  Number of pruned trials: \", len(pruned_trials))\n","    print(\"  Number of complete trials: \", len(complete_trials))\n","\n","    print(\"Best trial:\")\n","    trial = study.best_trial\n","\n","    print(\"  Value: \", trial.value)\n","\n","    print(\"  Params: \")\n","    for key, value in trial.params.items():\n","        print(\"    {}: {}\".format(key, value))"]},{"cell_type":"code","execution_count":68,"metadata":{"_uuid":"4782eb23fa7d003f0e2415d995894017edb2d896","id":"pRBBODBoWzL_"},"outputs":[{"ename":"NameError","evalue":"name 'model' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[68], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m predict \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict_generator(test_generator, steps\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mceil(nb_samples\u001b[39m/\u001b[39mbatch_size))\n","\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"]}],"source":["predict = model.predict_generator(test_generator, steps=np.ceil(nb_samples/batch_size))\n","# test_generator 자리 : 입력 샘플의 batch를 생성하는 생성기\n","# steps : 중지되기 전까지 generator로부터 얻는 단계의 총 갯수 (샘플의 batch) , np.ceil로 '올림'함\n"]},{"cell_type":"markdown","metadata":{"id":"aob1rYC_WzMA"},"source":["For categoral classication the prediction will come with probability of each category. So we will pick the category that have the highest probability with numpy average max"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SYmKTA9yWzMA"},"outputs":[],"source":["predict"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m3-aHjkuWzMA"},"outputs":[],"source":["np.argmax(predict, axis=-1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WZIjvBlvWzMB"},"outputs":[],"source":["test_df['category'] = np.argmax(predict, axis=-1) # axis에 해당하는 값들 중 가장 큰 값의 인덱스들을 반환하는 함수"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bfbuZO9kWzMB"},"outputs":[],"source":["test_df['category']"]},{"cell_type":"markdown","metadata":{"id":"2Ef-ywXYWzMC"},"source":["We will convert the predict category back into our generator classes by using `train_generator.class_indices`. It is the classes that image generator map while converting data into computer vision"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B2_R9ML5WzMC"},"outputs":[],"source":["dict((v,k) for k,v in train_generator.class_indices.items())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gcHgCSx0WzMC"},"outputs":[],"source":["label_map = dict((v,k) for k,v in train_generator.class_indices.items())\n","test_df['category'] = test_df['category'].replace(label_map) # test_df['category'] 값을 0 or 1을 cat or dog로 바꿈"]},{"cell_type":"markdown","metadata":{"id":"YprIiVfQWzMC"},"source":["From our prepare data part. We map data with `{1: 'dog', 0: 'cat'}`. Now we will map the result back to dog is 1 and cat is 0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GHbSKVjOWzMC"},"outputs":[],"source":["test_df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SE6SBzh_WzMD"},"outputs":[],"source":["test_df['category'] = test_df['category'].replace({ 'dog': 1, 'cat': 0 })"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W_RkEz6fWzMD"},"outputs":[],"source":["test_df"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"},"vscode":{"interpreter":{"hash":"9acc76a459d7db86261bc3c0fc1f5dcdadf57ce90dda3656ef3156477f1c2288"}}},"nbformat":4,"nbformat_minor":0}
